# (PART) Module 12 {-}




# Welcome to Cross Validation

This module is designed to introduce you to cross-validation. Please watch the videos and work your way through the notes. You can find the video playlist for this module [here][ds4p-pl-12]. Most of the slides used to make the videos in this module can be found in the [slides repo][ds4p-slides]. This week is a little bit delayed... 


```{=html}
<blockquote class="twitter-tweet" data-width="550" data-lang="en" data-dnt="true" data-theme="light"><p lang="en" dir="ltr">Don&#39;t do it. But also <a href="https://t.co/yrsvU0Xj1K">pic.twitter.com/yrsvU0Xj1K</a></p>&mdash; Bill Chopik (@Chops310) <a href="https://twitter.com/Chops310/status/1382481152489979913?ref_src=twsrc%5Etfw">April 14, 2021</a></blockquote>

```


## Module Materials

* Slides from Lectures
  * [Overfitting](https://datascience4psych.github.io/slides/d24_overfitting/d24_overfitting.html)
  * [Cross-validation](https://datascience4psych.github.io/slides/d25_crossvalidation/d25_crossvalidation.html)
* Suggested Readings
  * All subchapters of this module
  * Articles
    * [de Rooij, M., & Weeda, W. (2020). Cross-validation: A method every psychologist should know. Advances in Methods and Practices in Psychological Science, 3(2), 248-263.](https://journals.sagepub.com/doi/full/10.1177/2515245919898466)
    * [MacCallum, R. C., Zhang, S., Preacher, K. J., & Rucker, D. D. (2002). On the practice of dichotomization of quantitative variables. Psychological Methods, 7, 19-40.](http://www.quantpsy.org/pubs/maccallum_zhang_preacher_rucker_2002.pdf)
  * R4DS 
    * [Many Models](https://r4ds.had.co.nz/many-models.html)

# Overfitting!

You can follow along with the slides [here](https://datascience4psych.github.io/slides/d24_overfitting/d24_overfitting.html) if they do not appear below.


<iframe src="https://datascience4psych.github.io/slides/d24_overfitting/d24_overfitting.html#1" width="672" height="400px"></iframe>

## Prediction


```{=html}
<div class="vembedr" align="center">
<div>
<iframe src="https://www.youtube.com/embed/U70OmbO-DP4" width="533" height="300" frameborder="0" allowfullscreen=""></iframe>
</div>
</div>
```


<iframe src="https://datascience4psych.github.io/slides/d24_overfitting/d24_overfitting.html#2" width="672" height="400px"></iframe>


## Workflow

```{=html}
<div class="vembedr" align="center">
<div>
<iframe src="https://www.youtube.com/embed/R4h9u-sQHwI" width="533" height="300" frameborder="0" allowfullscreen=""></iframe>
</div>
</div>
```



<iframe src="https://datascience4psych.github.io/slides/d24_overfitting/d24_overfitting.html#17" width="672" height="400px"></iframe>


# Notes on Feature Engineering




## Feature engineering

- We prefer simple models when possible, but **parsimony** does not mean sacrificing accuracy (or predictive performance) in the interest of simplicity


- Variables that go into the model and how they are represented are just as critical to success of the model


- **Feature engineering** allows us to get creative with our predictors in an effort to make them more useful for our model (to increase its predictive performance) 



### Same training and testing sets as before


```r
# Fix random numbers by setting the seed 
# Enables analysis to be reproducible when random numbers are used 
set.seed(1066)

# Put 80% of the data into the training set 
email_split <- initial_split(email, prop = 0.80)

# Create data frames for the two sets:
train_data <- training(email_split)
test_data  <- testing(email_split)
```



### A simple approach: `mutate()`


```r
train_data %>%
  mutate(
    date = date(time),
    dow  = wday(time),
    month = month(time)
    ) %>%
  select(time, date, dow, month) %>%
  sample_n(size = 5) # shuffle to show a variety
#> # A tibble: 5 x 4
#>   time                date         dow month
#>   <dttm>              <date>     <dbl> <dbl>
#> 1 2012-01-27 09:07:50 2012-01-27     6     1
#> 2 2012-03-22 04:25:38 2012-03-22     5     3
#> 3 2012-03-16 22:06:15 2012-03-16     6     3
#> 4 2012-03-05 15:26:57 2012-03-05     2     3
#> 5 2012-02-13 12:31:43 2012-02-13     2     2
```



## Modeling workflow, revisited

- Create a **recipe** for feature engineering steps to be applied to the training data

- Fit the model to the training data after these steps have been applied


- Using the model estimates from the training data, predict outcomes for the test data


- Evaluate the performance of the model on the test data



## Building recipes



### Initiate a recipe


```r
email_rec <- recipe(
  spam ~ .,          # formula
  data = train_data  # data to use for cataloguing names and types of variables
  )

summary(email_rec)
```



```
#> # A tibble: 21 x 4
#>    variable     type    role      source  
#>    <chr>        <chr>   <chr>     <chr>   
#>  1 to_multiple  numeric predictor original
#>  2 from         numeric predictor original
#>  3 cc           numeric predictor original
#>  4 sent_email   numeric predictor original
#>  5 time         date    predictor original
#>  6 image        numeric predictor original
#>  7 attach       numeric predictor original
#>  8 dollar       numeric predictor original
#>  9 winner       nominal predictor original
#> 10 inherit      numeric predictor original
#> 11 viagra       numeric predictor original
#> 12 password     numeric predictor original
#> 13 num_char     numeric predictor original
#> 14 line_breaks  numeric predictor original
#> 15 format       numeric predictor original
#> 16 re_subj      numeric predictor original
#> 17 exclaim_subj numeric predictor original
#> 18 urgent_subj  numeric predictor original
#> 19 exclaim_mess numeric predictor original
#> 20 number       nominal predictor original
#> 21 spam         nominal outcome   original
```




### Remove certain variables


```r
email_rec <- email_rec %>%
  step_rm(from, sent_email)
```



```
#> Data Recipe
#> 
#> Inputs:
#> 
#>       role #variables
#>    outcome          1
#>  predictor         20
#> 
#> Operations:
#> 
#> Delete terms from, sent_email
```



### Feature engineer date


```r
email_rec <- email_rec %>%
  step_date(time, features = c("dow", "month")) %>%
  step_rm(time)
```



```
#> Data Recipe
#> 
#> Inputs:
#> 
#>       role #variables
#>    outcome          1
#>  predictor         20
#> 
#> Operations:
#> 
#> Delete terms from, sent_email
#> Date features from time
#> Delete terms time
```


### Discretize numeric variables

Procedue with major caution! And please be sure to read [MacCallum, R. C., Zhang, S., Preacher, K. J., & Rucker, D. D. (2002). On the practice of dichotomization of quantitative variables. Psychological Methods, 7, 19-40.](http://www.quantpsy.org/pubs/maccallum_zhang_preacher_rucker_2002.pdf) and play around with the demo data from Kris's website: http://www.quantpsy.org/mzpr.htm


```r
email_rec <- email_rec %>%
  step_cut(cc, attach, dollar, breaks = c(0, 1)) %>%
  step_cut(inherit, password, breaks = c(0, 1, 5, 10, 20))
```



```
#> Data Recipe
#> 
#> Inputs:
#> 
#>       role #variables
#>    outcome          1
#>  predictor         20
#> 
#> Operations:
#> 
#> Delete terms from, sent_email
#> Date features from time
#> Delete terms time
#> Cut numeric for cc, attach, dollar
#> Cut numeric for inherit, password
```




### Create dummy variables


```r
email_rec <- email_rec %>%
  step_dummy(all_nominal(), -all_outcomes())
```



```
#> Data Recipe
#> 
#> Inputs:
#> 
#>       role #variables
#>    outcome          1
#>  predictor         20
#> 
#> Operations:
#> 
#> Delete terms from, sent_email
#> Date features from time
#> Delete terms time
#> Cut numeric for cc, attach, dollar
#> Cut numeric for inherit, password
#> Dummy variables from all_nominal(), -all_outcomes()
```




### Remove zero variance variables

Variables that contain only a single value


```r
email_rec <- email_rec %>%
  step_zv(all_predictors())
```



```
#> Data Recipe
#> 
#> Inputs:
#> 
#>       role #variables
#>    outcome          1
#>  predictor         20
#> 
#> Operations:
#> 
#> Delete terms from, sent_email
#> Date features from time
#> Delete terms time
#> Cut numeric for cc, attach, dollar
#> Cut numeric for inherit, password
#> Dummy variables from all_nominal(), -all_outcomes()
#> Zero variance filter on all_predictors()
```


### All in one place


```r
email_rec <- recipe(spam ~ ., data = email) %>%
  step_rm(from, sent_email) %>%
  step_date(time, features = c("dow", "month")) %>%               
  step_rm(time) %>%
  step_cut(cc, attach, dollar, breaks = c(0, 1)) %>%
  step_cut(inherit, password, breaks = c(0, 1, 5, 10, 20)) %>%
  step_dummy(all_nominal(), -all_outcomes()) %>%
  step_zv(all_predictors())
```





## Building workflows

---

### Define model


```r
email_mod <- logistic_reg() %>% 
  set_engine("glm")

email_mod
#> Logistic Regression Model Specification (classification)
#> 
#> Computational engine: glm
```

### Define workflow

**Workflows** bring together models and recipes so that they can be easily applied to both the training and test data.


```r
email_wflow <- workflow() %>% 
  add_model(email_mod) %>% 
  add_recipe(email_rec)
```



```
#> == Workflow ========================================================================================
#> Preprocessor: Recipe
#> Model: logistic_reg()
#> 
#> -- Preprocessor ------------------------------------------------------------------------------------
#> 7 Recipe Steps
#> 
#> * step_rm()
#> * step_date()
#> * step_rm()
#> * step_cut()
#> * step_cut()
#> * step_dummy()
#> * step_zv()
#> 
#> -- Model -------------------------------------------------------------------------------------------
#> Logistic Regression Model Specification (classification)
#> 
#> Computational engine: glm
```


### Fit model to training data


```r
email_fit <- email_wflow %>% 
  fit(data = train_data)
```



```r
tidy(email_fit) %>% print(n = 31)
#> # A tibble: 31 x 5
#>    term               estimate std.error statistic  p.value
#>    <chr>                 <dbl>     <dbl>     <dbl>    <dbl>
#>  1 (Intercept)        -1.23      0.272     -4.51   6.56e- 6
#>  2 to_multiple        -2.83      0.396     -7.14   9.32e-13
#>  3 image              -1.17      0.638     -1.83   6.72e- 2
#>  4 viagra              2.30    182.         0.0127 9.90e- 1
#>  5 num_char            0.0691    0.0227     3.04   2.34e- 3
#>  6 line_breaks        -0.00581   0.00135   -4.31   1.66e- 5
#>  7 format             -0.779     0.160     -4.88   1.06e- 6
#>  8 re_subj            -2.82      0.408     -6.92   4.58e-12
#>  9 exclaim_subj       -0.203     0.295     -0.689  4.91e- 1
#> 10 urgent_subj         3.73      1.02       3.65   2.66e- 4
#> 11 exclaim_mess        0.00791   0.00177    4.47   8.00e- 6
#> 12 cc_X.1.68.          0.250     0.441      0.568  5.70e- 1
#> 13 attach_X.1.20.      2.03      0.406      5.00   5.86e- 7
#> 14 dollar_X.1.64.     -0.0614    0.231     -0.265  7.91e- 1
#> 15 winner_yes          1.88      0.423      4.44   8.99e- 6
#> 16 inherit_X.1.5.     -9.18    763.        -0.0120 9.90e- 1
#> 17 inherit_X.5.10.     3.06      1.46       2.09   3.66e- 2
#> 18 password_X.1.5.    -1.61      0.743     -2.17   2.98e- 2
#> 19 password_X.5.10.  -12.7     499.        -0.0254 9.80e- 1
#> 20 password_X.10.20. -13.9     803.        -0.0173 9.86e- 1
#> 21 password_X.20.28. -13.9     803.        -0.0173 9.86e- 1
#> 22 number_small       -1.02      0.170     -5.98   2.30e- 9
#> 23 number_big         -0.00783   0.240     -0.0326 9.74e- 1
#> 24 time_dow_Mon        0.212     0.316      0.670  5.03e- 1
#> 25 time_dow_Tue        0.595     0.290      2.06   3.98e- 2
#> 26 time_dow_Wed        0.0847    0.297      0.286  7.75e- 1
#> 27 time_dow_Thu        0.415     0.295      1.41   1.59e- 1
#> 28 time_dow_Fri        0.393     0.293      1.34   1.81e- 1
#> 29 time_dow_Sat        0.496     0.319      1.55   1.20e- 1
#> 30 time_month_Feb      0.767     0.184      4.16   3.14e- 5
#> 31 time_month_Mar      0.554     0.184      3.00   2.68e- 3
```


### Make predictions for test data


```r
email_pred <- predict(email_fit, test_data, type = "prob") %>% 
  bind_cols(test_data) 
#> Warning: There are new levels in a factor: NA

email_pred
#> # A tibble: 784 x 23
#>    .pred_0  .pred_1 spam  to_multiple  from    cc sent_email time                image attach dollar
#>      <dbl>    <dbl> <fct>       <dbl> <dbl> <int>      <dbl> <dttm>              <dbl>  <dbl>  <dbl>
#>  1   0.996 0.00361  0               1     1     0          1 2012-01-01 12:55:06     0      0      0
#>  2   0.919 0.0813   0               0     1     0          0 2012-01-01 16:08:59     0      0      0
#>  3   0.957 0.0435   0               0     1     0          1 2012-01-01 13:23:44     0      0      0
#>  4   0.999 0.00114  0               0     1     1          1 2012-01-01 14:38:32     0      0      0
#>  5   0.994 0.00550  0               0     1     0          1 2012-01-01 20:40:40     0      0      0
#>  6   0.994 0.00602  0               0     1     0          1 2012-01-01 21:07:20     0      0      0
#>  7   0.888 0.112    0               0     1     0          0 2012-01-01 21:08:14     0      0      0
#>  8   0.994 0.00570  0               0     1     0          0 2012-01-01 21:51:24     0      0      0
#>  9   0.995 0.00521  0               0     1     1          0 2012-01-01 22:16:39     0      0      0
#> 10   1.00  0.000249 0               1     1     3          0 2012-01-02 08:41:11     0      0      0
#> # ... with 774 more rows, and 12 more variables: winner <fct>, inherit <dbl>, viagra <dbl>,
#> #   password <dbl>, num_char <dbl>, line_breaks <int>, format <dbl>, re_subj <dbl>,
#> #   exclaim_subj <dbl>, urgent_subj <dbl>, exclaim_mess <dbl>, number <fct>
```



### Evaluate the performance



```r
email_pred %>%
  roc_curve(
    truth = spam,
    .pred_1,
    event_level = "second"
  ) %>%
  autoplot()
```

<img src="1201_cv_files/figure-html/roc-1.png" width="672" />




```r
email_pred %>%
  roc_auc(
    truth = spam,
    .pred_1,
    event_level = "second"
  )
#> # A tibble: 1 x 3
#>   .metric .estimator .estimate
#>   <chr>   <chr>          <dbl>
#> 1 roc_auc binary         0.865
```



## Making decisions


### Cutoff probability: 0.5

Suppose we decide to label an email as spam if the model predicts the probability of spam to be **more than 0.5**.



```r
cutoff_prob <- 0.5
email_pred %>%
  mutate(
    spam      = if_else(spam == 1, "Email is spam", "Email is not spam"),
    spam_pred = if_else(.pred_1 > cutoff_prob, "Email labelled spam", "Email labelled not spam")
    ) %>%
  count(spam_pred, spam) %>%
  pivot_wider(names_from = spam, values_from = n) %>%
  kable(col.names = c("", "Email is not spam", "Email is spam"))
```



|                        | Email is not spam| Email is spam|
|:-----------------------|-----------------:|-------------:|
|Email labelled not spam |               699|            68|
|Email labelled spam     |                 6|            10|
|NA                      |                 1|            NA|




### Cutoff probability: 0.25



Suppose we decide to label an email as spam if the model predicts the probability of spam to be **more than 0.25**.



```r
cutoff_prob <- 0.25
email_pred %>%
  mutate(
    spam      = if_else(spam == 1, "Email is spam", "Email is not spam"),
    spam_pred = if_else(.pred_1 > cutoff_prob, "Email labelled spam", "Email labelled not spam")
    ) %>%
  count(spam_pred, spam) %>%
  pivot_wider(names_from = spam, values_from = n) %>%
  kable(col.names = c("", "Email is not spam", "Email is spam"))
```



|                        | Email is not spam| Email is spam|
|:-----------------------|-----------------:|-------------:|
|Email labelled not spam |               667|            49|
|Email labelled spam     |                38|            29|
|NA                      |                 1|            NA|



### Cutoff probability: 0.75

Suppose we decide to label an email as spam if the model predicts the probability of spam to be **more than 0.75**.


```r
cutoff_prob <- 0.75
email_pred %>%
  mutate(
    spam      = if_else(spam == 1, "Email is spam", "Email is not spam"),
    spam_pred = if_else(.pred_1 > cutoff_prob, "Email labelled spam", "Email labelled not spam")
    ) %>%
  count(spam_pred, spam) %>%
  pivot_wider(names_from = spam, values_from = n) %>%
  kable(col.names = c("", "Email is not spam", "Email is spam"))
```



|                        | Email is not spam| Email is spam|
|:-----------------------|-----------------:|-------------:|
|Email labelled not spam |               704|            72|
|Email labelled spam     |                 1|             6|
|NA                      |                 1|            NA|

# Cross-Validation

You can follow along with the slides [here](https://datascience4psych.github.io/slides/d25_crossvalidation/d25_crossvalidation.html) if they do not appear below.


```{=html}
<div class="vembedr" align="center">
<div>
<iframe src="https://www.youtube.com/embed/KQ9f8s7RB5g" width="533" height="300" frameborder="0" allowfullscreen=""></iframe>
</div>
</div>
```



<iframe src="https://datascience4psych.github.io/slides/d25_crossvalidation/d25_crossvalidation.html" width="672" height="400px"></iframe>

## V-Fold

```{=html}
<div class="vembedr" align="center">
<div>
<iframe src="https://www.youtube.com/embed/quEVKV-Tk0Y" width="533" height="300" frameborder="0" allowfullscreen=""></iframe>
</div>
</div>
```



<iframe src="https://datascience4psych.github.io/slides/d25_crossvalidation/d25_crossvalidation.html#35" width="672" height="400px"></iframe>
